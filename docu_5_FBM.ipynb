{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1035a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcffd5a7",
   "metadata": {},
   "source": [
    "FBM_LSTM不如LSTM好用，LSTM/GRU 是局部建模器，只适合短期记忆，我打算用FBM-NP，更适合长期预测\n",
    "\n",
    "我打算用FBM-NL + 多步收益率预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de06eb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#配置参数\n",
    "T = 128  # 每个滑动窗口的时间序列长度（即模型输入序列长度）\n",
    "L = 1    # 预测步数（例如预测下一个 close 价格）\n",
    "stride = 1 #滑动窗口的步长\n",
    "num_epochs = 50 # 模型训练的轮数\n",
    "batch_size = 32 # 每一批训练样本的数量\n",
    "\n",
    "# 自动选择设备（如果有GPU就用GPU，否则用CPU）\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c3ffc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据读取与滑窗\n",
    "df = pd.read_csv('SP500.csv', parse_dates=['date'])\n",
    "df.sort_values('date', inplace=True)\n",
    "close = df['close'].values\n",
    "returns = np.diff(np.log(close))  # 对数的收益率\n",
    "\n",
    "# 检查输入长度T是否是偶数\n",
    "if T % 2 != 0:\n",
    "    T += 1\n",
    "\n",
    "# 生成滑窗和目标\n",
    "data = np.lib.stride_tricks.sliding_window_view(returns, window_shape=T)[::stride]\n",
    "y = returns[T + (L - 1):]  # 预测L步后的值\n",
    "X_raw = data[:len(y)]  # 适配X和y的长度\n",
    "X_raw = (X_raw - X_raw.mean()) / (X_raw.std() + 1e-8)  # 原始输入平稳化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5970204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通用 Dataset 类\n",
    "#将输入特征 X 和目标标签 y 封装为 PyTorch 可处理的数据集，好进行一些操作\n",
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)#将输入特征转换为 float32 类型的张量\n",
    "        self.y = torch.tensor(y, dtype=torch.float32).unsqueeze(-1)#在最后一维添加维度\n",
    "    def __len__(self):#返回数据集的样本数量\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):#根据索引 idx 返回对应的特征和标签样本\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e4cf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FBM特征生成函数\n",
    "#输入长度为T的一维数组，输出二维数组\n",
    "def fbm_features(x):\n",
    "    T = len(x)\n",
    "    H = np.fft.fft(x) # 傅里叶变换\n",
    "    HR, HI = H.real, H.imag\n",
    "    K = T // 2 + 1\n",
    "    N = np.arange(T).reshape(-1, 1)# 时间索引列向量 (T, 1)\n",
    "    ks = np.arange(K).reshape(1, -1)# 频率索引行向量 (1, K)\n",
    "\n",
    "    # 生成正交基函数矩阵 (文献公式5和6)\n",
    "    C = np.cos(2 * np.pi * N @ ks / T)/T\n",
    "    S = -np.sin(2 * np.pi * N @ ks / T)/T\n",
    "\n",
    "    #初始化频域系数 (文献公式7和8)\n",
    "    ak = np.zeros(K)\n",
    "    bk = np.zeros(K)\n",
    "    ak[0] = HR[0]          # 直流分量\n",
    "    bk[0] = 0              # 直流分量无虚部\n",
    "    ak[-1] = HR[T//2]      # 奈奎斯特频率分量\n",
    "    bk[-1] = 0             # 奈奎斯特频率分量无虚部\n",
    "    ak[1:-1] = 2 * HR[1:T//2]  # 中间频率分量实部缩放\n",
    "    bk[1:-1] = 2 * HI[1:T//2]  # 中间频率分量虚部缩放\n",
    "    \n",
    "    fbm_feature = np.concatenate([C * ak, S * bk], axis=1)\n",
    "    fbm_feature = (fbm_feature - fbm_feature.mean()) / (fbm_feature.std() + 1e-8)\n",
    "    return fbm_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de926345",
   "metadata": {},
   "outputs": [],
   "source": [
    "fbm_tensor = np.stack([fbm_features(x) for x in X_raw], axis=0)\n",
    "X_fbm = fbm_tensor[:len(y)]\n",
    "X_raw = X_raw[:, :, np.newaxis]  # 输入调整维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de5521c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 顺序分割数据，防止时间混淆\n",
    "train_size = int(0.8 * len(X_raw))\n",
    "train_raw = SeqDataset(X_raw[:train_size], y[:train_size])\n",
    "val_raw = SeqDataset(X_raw[train_size:], y[train_size:])\n",
    "train_fbm = SeqDataset(X_fbm[:train_size], y[:train_size])\n",
    "val_fbm = SeqDataset(X_fbm[train_size:], y[train_size:])\n",
    "\n",
    "train_loader_raw = DataLoader(train_raw, batch_size=batch_size, shuffle=True)\n",
    "val_loader_raw = DataLoader(val_raw, batch_size=batch_size)\n",
    "train_loader_fbm = DataLoader(train_fbm, batch_size=batch_size, shuffle=True)\n",
    "val_loader_fbm = DataLoader(val_fbm, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08c7b4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 网络结构\n",
    "#LSTMModel 是一个继承自 PyTorch nn.Module 的神经网络模型：LSTM层（提取序列中的时序特征）+全连接层（将 LSTM 的输出映射到最终预测值）\n",
    "class FBM_LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=256, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.norm = nn.LayerNorm(hidden_dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim // 2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.norm(out[:, -1, :])\n",
    "        return self.mlp(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6a20b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证函数\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in dataloader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            pred = model(x_batch).cpu().numpy()\n",
    "            y_true.append(y_batch.numpy())\n",
    "            y_pred.append(pred)\n",
    "    y_true = np.concatenate(y_true).flatten()\n",
    "    y_pred = np.concatenate(y_pred).flatten()\n",
    "    return mean_absolute_error(y_true, y_pred), np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a323b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练函数\n",
    "def train_model(model, train_loader, val_loader,patience=5):\n",
    "    model.to(device)#将模型移至指定设备（CPU/GPU）\n",
    "    #Adam 优化器：自适应学习率优化算法\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=patience//2)\n",
    "    criterion = nn.MSELoss()#均方误差损失函数\n",
    "    best_val_mae = float('inf')\n",
    "    early_stop_counter = 0\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()#设置训练模式：启用 Dropout 等训练专用层\n",
    "        total_loss = 0\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()#防止梯度累积\n",
    "            loss = criterion(model(x_batch), y_batch)\n",
    "            loss.backward()#反向传播,计算梯度\n",
    "            optimizer.step()#更新模型权重\n",
    "            total_loss += loss.item()#记录本轮总损失\n",
    "        \n",
    "\n",
    "        # 验证阶段\n",
    "        val_mae, val_rmse = evaluate_model(model, val_loader)\n",
    "        scheduler.step(val_mae)\n",
    "\n",
    "        \n",
    "        # 早停机制\n",
    "        if val_mae < best_val_mae:\n",
    "            best_val_mae = val_mae\n",
    "            best_model = model.state_dict()\n",
    "            early_stop_counter = 0\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            if early_stop_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "        \n",
    "        print(f\"Epoch {epoch:02d}: TrainLoss={total_loss/len(train_loader):.4f}, Val MAE={val_mae:.4f}, RMSE={val_rmse:.4f}\")\n",
    "\n",
    "    \n",
    "    # 加载最佳模型\n",
    "    model.load_state_dict(best_model)\n",
    "    return model, best_val_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "08c6af7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Training baseline LSTM...\n",
      "Epoch 01: TrainLoss=0.0126, Val MAE=0.0066, RMSE=0.0122\n",
      "Epoch 02: TrainLoss=0.0002, Val MAE=0.0066, RMSE=0.0123\n",
      "Epoch 03: TrainLoss=0.0002, Val MAE=0.0066, RMSE=0.0121\n",
      "Epoch 04: TrainLoss=0.0002, Val MAE=0.0066, RMSE=0.0121\n",
      "Epoch 05: TrainLoss=0.0002, Val MAE=0.0066, RMSE=0.0121\n",
      "Epoch 06: TrainLoss=0.0002, Val MAE=0.0066, RMSE=0.0121\n",
      "Epoch 07: TrainLoss=0.0002, Val MAE=0.0066, RMSE=0.0121\n",
      "Epoch 08: TrainLoss=0.0002, Val MAE=0.0066, RMSE=0.0120\n",
      "Epoch 09: TrainLoss=0.0002, Val MAE=0.0066, RMSE=0.0120\n",
      "Epoch 10: TrainLoss=0.0002, Val MAE=0.0066, RMSE=0.0120\n",
      "Epoch 11: TrainLoss=0.0002, Val MAE=0.0066, RMSE=0.0121\n",
      "Epoch 12: TrainLoss=0.0002, Val MAE=0.0066, RMSE=0.0121\n",
      "Epoch 13: TrainLoss=0.0002, Val MAE=0.0066, RMSE=0.0121\n",
      "Early stopping at epoch 14\n"
     ]
    }
   ],
   "source": [
    "# 训练 baseline LSTM（原始序列）:定义模型、训练模型、评估模型\n",
    "print(\"\\n🔹 Training baseline LSTM...\")\n",
    "model_raw = FBM_LSTM(input_dim=1)  # 保持同一结构\n",
    "model_raw, _ = train_model(model_raw, train_loader_raw, val_loader_raw)\n",
    "mae_raw, rmse_raw = evaluate_model(model_raw, val_loader_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f6777778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Training FBM-LSTM...\n",
      "Epoch 01: TrainLoss=0.0088, Val MAE=0.0091, RMSE=0.0136\n",
      "Epoch 02: TrainLoss=0.0003, Val MAE=0.0102, RMSE=0.0142\n",
      "Epoch 03: TrainLoss=0.0003, Val MAE=0.0105, RMSE=0.0144\n",
      "Epoch 04: TrainLoss=0.0002, Val MAE=0.0080, RMSE=0.0131\n",
      "Epoch 05: TrainLoss=0.0002, Val MAE=0.0070, RMSE=0.0123\n",
      "Epoch 06: TrainLoss=0.0002, Val MAE=0.0071, RMSE=0.0123\n",
      "Epoch 07: TrainLoss=0.0002, Val MAE=0.0084, RMSE=0.0130\n",
      "Epoch 08: TrainLoss=0.0002, Val MAE=0.0068, RMSE=0.0122\n",
      "Epoch 09: TrainLoss=0.0002, Val MAE=0.0082, RMSE=0.0128\n",
      "Epoch 10: TrainLoss=0.0002, Val MAE=0.0067, RMSE=0.0122\n",
      "Epoch 11: TrainLoss=0.0002, Val MAE=0.0069, RMSE=0.0123\n",
      "Epoch 12: TrainLoss=0.0002, Val MAE=0.0067, RMSE=0.0120\n",
      "Epoch 13: TrainLoss=0.0001, Val MAE=0.0070, RMSE=0.0128\n",
      "Epoch 14: TrainLoss=0.0001, Val MAE=0.0067, RMSE=0.0120\n",
      "Epoch 15: TrainLoss=0.0001, Val MAE=0.0068, RMSE=0.0121\n",
      "Epoch 16: TrainLoss=0.0001, Val MAE=0.0069, RMSE=0.0123\n",
      "Early stopping at epoch 17\n"
     ]
    }
   ],
   "source": [
    "# 训练 FBM-LSTM（FBM特征）\n",
    "print(\"\\n🔹 Training FBM-LSTM...\")\n",
    "model_fbm = FBM_LSTM(input_dim=X_fbm.shape[2])\n",
    "model_fbm, _ = train_model(model_fbm, train_loader_fbm, val_loader_fbm)\n",
    "mae_fbm, rmse_fbm = evaluate_model(model_fbm, val_loader_fbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dd412a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Final Evaluation:\n",
      "LSTM       → MAE: 0.0066, RMSE: 0.0121\n",
      "FBM-LSTM   → MAE: 0.0068, RMSE: 0.0123\n"
     ]
    }
   ],
   "source": [
    "# 输出最终对比结果\n",
    "print(\"\\n✅ Final Evaluation:\")\n",
    "print(f\"LSTM       → MAE: {mae_raw:.4f}, RMSE: {rmse_raw:.4f}\")\n",
    "print(f\"FBM-LSTM   → MAE: {mae_fbm:.4f}, RMSE: {rmse_fbm:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
